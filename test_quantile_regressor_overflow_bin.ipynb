{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import string_constants as sc\n",
    "import reading_util as ru\n",
    "import writing_util as wu\n",
    "import dataset_util as du\n",
    "import parameter as pa\n",
    "import quantile_regression_dnn as qr\n",
    "import data_sample as ds\n",
    "import plotting_util as pu\n",
    "import plotting_util_analysis as pua\n",
    "import flat_cut as fc\n",
    "import selector as sr\n",
    "import discriminator as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_run_path( strategy, quantile, selector ):\n",
    "    return os.path.join( strategy.path_str,  quantile.path_str, selector.path_str )\n",
    "\n",
    "def make_run_title( strategy, quantile, selector ):\n",
    "    return strategy.title_str + ' ' + quantile.title_str + ' ' + selector.title_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of total qcd signal region data for QR training (rest for GOF test)\n",
    "QR_train_share = 0.25 #0.2\n",
    "# constant fraction wrt dijet mass of BG accepted\n",
    "quantile = pa.quantile_dict['q10'] # q1 = 1%\n",
    "# strategy for combining loss-jet-1 and loss-jet-2\n",
    "strategy = pa.loss_strategy_dict['s5'] # s5 = L1 & L2\n",
    "# discriminator accepted - rejected\n",
    "selector = pa.selector_dict['qr_full']\n",
    "# make path\n",
    "pathstr = make_run_path( strategy, quantile, selector )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date.today().strftime(\"%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data (qcd and signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_sample = 'qcdSigAll'\n",
    "qcd_path = os.path.join( sc.concat_result_dir, sc.sample_loc[SM_sample] + sc.concat_result_suffix )\n",
    "qcd_data_total = ru.read_results_to_dataframe( qcd_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split qcd data into train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_data_train, qcd_data_test = du.split_dataset_train_test( qcd_data_total, QR_train_share )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make qcd_train and qcd_test data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_sample_train = ds.DataSample( SM_sample+'_train', qcd_data_train )\n",
    "qcd_sample_test = ds.DataSample( SM_sample, qcd_data_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,601\n",
      "Trainable params: 30,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1053912 samples, validate on 263478 samples\n",
      "Epoch 1/100\n",
      " - 25s - loss: 0.1011 - val_loss: 0.0054\n",
      "Epoch 2/100\n",
      " - 24s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 3/100\n",
      " - 23s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 4/100\n",
      " - 24s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000200000009499.\n",
      " - 24s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 6/100\n",
      " - 24s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 7/100\n",
      " - 22s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.00000018999e-05.\n",
      " - 22s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 9/100\n",
      " - 22s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 10/100\n",
      " - 22s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.0000005255e-06.\n",
      " - 21s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 12/100\n",
      " - 22s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-20 14:06:35.527990: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "discriminator = dm.Discriminator( quantile, strategy, selector )\n",
    "discriminator.train_selector( qcd_sample_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/minl1l2_loss/qu_10pct/QR_full\n",
      "models/minl1l2_loss/qu_10pct/QR_full/model_0520_run_6.h5\n"
     ]
    }
   ],
   "source": [
    "model_base_path = os.path.join('models',pathstr)\n",
    "print(model_base_path)\n",
    "!mkdir -p $model_base_path\n",
    "run = 6\n",
    "model_path = 'model_'+date+'_run_'+str(run)+'.h5'\n",
    "print(os.path.join(model_base_path, model_path))\n",
    "discriminator.save_selector(os.path.join(model_base_path, model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
